{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06100a-d92a-4f8c-a95b-fe6ccf7986f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY CONFIGURATION\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API Key from the environment variable\n",
    "API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "# Input parameters that can be modified\n",
    "config = {\n",
    "    \"query\": \"juicio alvaro uribe\",\n",
    "    \"published_after\": \"2024-01-01T00:00:00Z\",\n",
    "    \"published_before\": \"2025-04-13T23:59:59Z\",\n",
    "    \"min_views\": 100,\n",
    "    \"min_comments\": 20,\n",
    "    \"max_comments\": 10000, # Max number of comments to read\n",
    "    \"max_results\": 2000  #  Max number of results to fetch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef997e7f-d2cc-4c40-81c5-fe7552008ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search YouTube videos based on the configuration\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def search_videos():\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(videos) < config[\"max_results\"]:\n",
    "        print(f\"Buscando videos... ({len(videos)}/{config['max_results']})\")\n",
    "        \n",
    "        url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"q\": config[\"query\"],\n",
    "            \"type\": \"video\",\n",
    "            \"order\": \"date\",\n",
    "            \"publishedAfter\": config[\"published_after\"],\n",
    "            \"publishedBefore\": config[\"published_before\"],\n",
    "            \"maxResults\": 50,  # Max results per request\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "        if next_page_token:\n",
    "            params[\"pageToken\"] = next_page_token\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        # Check for errors in the response\n",
    "        video_ids = [item[\"id\"][\"videoId\"] for item in data.get(\"items\", [])]\n",
    "        if not video_ids:\n",
    "            break\n",
    "\n",
    "        # Fetch video details for the found video IDs\n",
    "        details = get_video_details(video_ids)\n",
    "        for video in details:\n",
    "            views = int(video.get(\"statistics\", {}).get(\"viewCount\", 0))\n",
    "            comments = int(video.get(\"statistics\", {}).get(\"commentCount\", 0))\n",
    "            if views >= config[\"min_views\"] and comments >= config[\"min_comments\"]:\n",
    "                videos.append(video)\n",
    "                if len(videos) >= config[\"max_results\"]:\n",
    "                    break\n",
    "\n",
    "        next_page_token = data.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    print(f\"Total de videos encontrados que cumplen filtros: {len(videos)}\")\n",
    "    return videos\n",
    "\n",
    "def get_video_details(video_ids):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "    params = {\n",
    "        \"part\": \"snippet,statistics,contentDetails\",\n",
    "        \"id\": \",\".join(video_ids),\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json().get(\"items\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a336b3e-579f-480b-ae6a-5babc588a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct search test and display of video titles\n",
    "videos = search_videos()\n",
    "for v in videos[:3]:  # Display only the first 3 videos\n",
    "    print(\"Video:\", v[\"snippet\"][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba67e5-2968-4bcd-ab0d-777e2cbb8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRELIMINARY STORAGE OF VIDEO FILE\n",
    "import pandas as pd\n",
    "from isodate import parse_duration\n",
    "import os\n",
    "\n",
    "def save_videos_to_csv(videos, output_path=\"../data/videos_preliminares.csv\"):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    for v in videos:\n",
    "        stats = v.get(\"statistics\", {})\n",
    "        snippet = v.get(\"snippet\", {})\n",
    "        content = v.get(\"contentDetails\", {})\n",
    "        rows.append({\n",
    "            \"video_id\": v[\"id\"],\n",
    "            \"title\": snippet.get(\"title\"),\n",
    "            \"publishedAt\": snippet.get(\"publishedAt\"),\n",
    "            \"channel_id\": snippet.get(\"channelId\"),\n",
    "            \"channel_title\": snippet.get(\"channelTitle\"),\n",
    "            \"views\": stats.get(\"viewCount\"),\n",
    "            \"likes\": stats.get(\"likeCount\"),\n",
    "            #\"dilikes\": stats.get(\"dilikeCount\"), No disponible en la API\n",
    "            #\"favorite\": stats.get(\"favoriteCount\"), No disponible en la API\n",
    "            \"comments\": stats.get(\"commentCount\"),\n",
    "            \"description\": snippet.get(\"description\"),\n",
    "            \"video_tags\": \", \".join(snippet.get(\"tags\", [])),\n",
    "            \"duration_seconds\" : int(parse_duration(content.get(\"duration\")).total_seconds()),\n",
    "            #\"video_category\": snippet.get(\"categoryId\"),\n",
    "            #\"default_audio_language\": snippet.get(\"defaultAudioLanguage\"),\n",
    "            \"video_url\": f\"https://www.youtube.com/watch?v={v['id']}\"\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df_sind = df.drop_duplicates()\n",
    "    if(df.shape[0]>df_sind.shape[0]):\n",
    "        print(f\"Se encontraron {df.shape[0]-df_sind.shape[0]} videos duplicados. Los duplicados fueron removidos.\")\n",
    "        \n",
    "    df_sind.to_csv(output_path, index=False)\n",
    "    print(f\"Videos preliminares guardados en: {output_path}\")\n",
    "\n",
    "# If run directly, execute the search and save the results\n",
    "save_videos_to_csv(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb31d3-aaab-49f0-9fac-a1a0cf6fdc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITION OF CHANNEL METADATA\n",
    "\n",
    "def get_channel_metadata(channel_ids):\n",
    "    channel_info = {}\n",
    "    for chunk in chunks(channel_ids, 50):  # API allows 50 IDs per request\n",
    "        url = \"https://www.googleapis.com/youtube/v3/channels\"\n",
    "        params = {\n",
    "            \"part\": \"snippet,statistics\",\n",
    "            \"id\": \",\".join(chunk),\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "        res = requests.get(url, params=params).json()\n",
    "        for item in res.get(\"items\", []):\n",
    "            channel_info[item[\"id\"]] = {\n",
    "                \"channel_subscribers\": item[\"statistics\"].get(\"subscriberCount\"),\n",
    "                \"channel_country\": item[\"snippet\"].get(\"country\")\n",
    "            }\n",
    "    return channel_info\n",
    "\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Split the list into chunks of at most n elements.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def enrich_video_data(input_csv=\"../data/videos_preliminares.csv\"):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    print(\"Obteniendo metadatos de canales...\")\n",
    "    channel_data = get_channel_metadata(df[\"channel_id\"].unique().tolist())\n",
    "\n",
    "    # Add to the DataFrame\n",
    "    df[\"channel_subscribers\"] = df[\"channel_id\"].map(lambda x: channel_data.get(x, {}).get(\"channel_subscribers\"))\n",
    "    df[\"channel_country\"] = df[\"channel_id\"].map(lambda x: channel_data.get(x, {}).get(\"channel_country\"))\n",
    "\n",
    "    df.to_csv(input_csv, index=False)\n",
    "    print(f\"Archivo actualizado con metadatos enriquecidos: {input_csv}\")\n",
    "\n",
    "\n",
    "enrich_video_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933044a7-a261-47c0-b07a-b47d08d6e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET COMMENTS\n",
    "\n",
    "def get_comments_for_video(video_id, max_comments=100):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(comments) < max_comments:\n",
    "        url = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "        params = {\n",
    "            \"part\": \"snippet,replies\",\n",
    "            \"videoId\": video_id,\n",
    "            \"maxResults\": 100,\n",
    "            \"textFormat\": \"plainText\",\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "        if next_page_token:\n",
    "            params[\"pageToken\"] = next_page_token\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        for item in data.get(\"items\", []):\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comment_data = {\n",
    "                \"video_id\": video_id,\n",
    "                \"comment_id\": item[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                \"text\": comment[\"textDisplay\"],\n",
    "                \"author_name\": comment[\"authorDisplayName\"],\n",
    "                \"author_id\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorChannelId\"][\"value\"],\n",
    "                \"published_at\": comment[\"publishedAt\"],\n",
    "                \"likes\": comment[\"likeCount\"],\n",
    "                \"is_reply\": False,\n",
    "                \"reply_to_comment_id\": None\n",
    "            }\n",
    "            comments.append(comment_data)\n",
    "\n",
    "            # If there are replies, capture those as well\n",
    "            if \"replies\" in item:\n",
    "                for reply in item[\"replies\"][\"comments\"]:\n",
    "                    reply_data = reply[\"snippet\"]\n",
    "                    comments.append({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"comment_id\": reply[\"id\"],\n",
    "                        \"text\": reply_data[\"textDisplay\"],\n",
    "                        \"author_name\": reply_data[\"authorDisplayName\"],\n",
    "                        \"author_id\": reply[\"snippet\"][\"authorChannelId\"][\"value\"],\n",
    "                        \"published_at\": reply_data[\"publishedAt\"],\n",
    "                        \"likes\": reply_data[\"likeCount\"],\n",
    "                        \"is_reply\": True,\n",
    "                        \"reply_to_comment_id\": item[\"snippet\"][\"topLevelComment\"][\"id\"]\n",
    "                    })\n",
    "\n",
    "        next_page_token = data.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "def get_all_comments(video_ids, max_comments=100):\n",
    "    all_comments = []\n",
    "    count = 1\n",
    "    for video_id in video_ids:\n",
    "        print(f\"Obteniendo comentarios para el video ({count}): {video_id}\")\n",
    "        comments = get_comments_for_video(video_id, max_comments)\n",
    "        all_comments.extend(comments)\n",
    "        count += 1\n",
    "    return all_comments\n",
    "\n",
    "def save_comments_to_csv(comments, output_path=\"../data/comments.csv\"):\n",
    "    df = pd.DataFrame(comments)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Comentarios guardados en: {output_path}\")\n",
    "\n",
    "\n",
    "# Load video IDs from the preliminary videos CSV\n",
    "videos_df = pd.read_csv(\"../data/videos_preliminares.csv\")\n",
    "video_ids = videos_df[\"video_id\"].tolist()\n",
    "\n",
    "# Get comments for all videos\n",
    "comments = get_all_comments(video_ids, max_comments = config[\"max_comments\"])\n",
    "\n",
    "# Save comments to CSV\n",
    "save_comments_to_csv(comments) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
