{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13f8ad3",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c98f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# classification libraries\n",
    "from openai import OpenAI, RateLimitError, APIError, Timeout, APIConnectionError\n",
    "\n",
    "# retry libraries\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607145bc",
   "metadata": {},
   "source": [
    "# GPT Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e61bae",
   "metadata": {},
   "source": [
    "## Classificator Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53bca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI4_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI4_API_KEY not found in environment variables\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Classification Function\n",
    "@retry(\n",
    "    retry=retry_if_exception_type((RateLimitError, APIError, Timeout, APIConnectionError)),\n",
    "    wait=wait_random_exponential(min=5, max=60),\n",
    "    stop=stop_after_attempt(6)\n",
    ")\n",
    "def openAI_classificator(context, message, model=\"gpt-4.1-2025-04-14\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": context\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": message\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=10, \n",
    "            temperature=0.0,\n",
    "            top_p=0.9\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content, response.usage.total_tokens\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        match = re.search(r\"Requested (\\d+)\\.\", str(e))\n",
    "        if match:\n",
    "            requested_tokens = int(match.group(1))\n",
    "        else:\n",
    "            requested_tokens = 0\n",
    "        \n",
    "        return np.nan, requested_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679a185",
   "metadata": {},
   "source": [
    "## Token Limit Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004efb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max token per minute \n",
    "MAX_TOKENS_PER_MINUTE = 450000 # Rate limit tier 2 -> 450k tokens/minute in model gpt-4.1-2025-04-14\n",
    "\n",
    "# save (timestamp, tokens) of each request in a deque\n",
    "token_window = deque()\n",
    "\n",
    "def clean_token_window():\n",
    "    #delete the values older than 60 seconds\n",
    "    current_time = time.time()\n",
    "    while token_window and (current_time - token_window[0][0]) > 60:\n",
    "        token_window.popleft()\n",
    "\n",
    "def wait_if_needed(new_tokens):\n",
    "    clean_token_window()\n",
    "    current_tokens = sum(tokens for _, tokens in token_window)\n",
    "\n",
    "    if current_tokens + new_tokens > MAX_TOKENS_PER_MINUTE:\n",
    "        excess = (current_tokens + new_tokens) - MAX_TOKENS_PER_MINUTE\n",
    "        print(f\"[WAIT] amount of tokens exceded ({excess}). Waiting...\")\n",
    "\n",
    "        # Calculate the time to wait based on the excess tokens\n",
    "        time_to_wait = 60 - (time.time() - token_window[0][0])\n",
    "        time.sleep(time_to_wait)\n",
    "        clean_token_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce27d0",
   "metadata": {},
   "source": [
    "## Context and Subject Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7060173",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"your context goes here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"your subject goes here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452dc81",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileC = \"your file path with comments goes here\"\n",
    "dfC = pd.read_csv(fileC, dtype={\"classification\": str, \"polarity\":str})\n",
    "\n",
    "fileV = \"your file path with video classification goes here\"\n",
    "dfV = pd.read_csv(fileV, dtype={\"classification\": str, \"polarity\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_tag(video_stance):\n",
    "    try:\n",
    "        video_stance = int(video_stance)\n",
    "    except ValueError:\n",
    "        return np.nan    \n",
    "    \n",
    "    if video_stance == 1:\n",
    "        return \"completamente en desacuerdo\"\n",
    "    elif video_stance == 2:\n",
    "        return \"en desacuerdo\"\n",
    "    elif video_stance == 3:\n",
    "        return \"ni de acuerdo ni en desacuerdo\"\n",
    "    elif video_stance == 4:\n",
    "        return \"de acuerdo\"\n",
    "    elif video_stance == 5:\n",
    "        return \"completamente de acuerdo\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_sentiment_tag(video_sentiment):\n",
    "    try:\n",
    "        video_sentiment = int(video_sentiment)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "    if video_sentiment == 1 :\n",
    "        return \"negativo\"\n",
    "    elif video_sentiment == 2:\n",
    "        return \"neutral\"\n",
    "    elif video_sentiment == 3:\n",
    "        return \"positivo\"\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad46988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_prompt(context,subject, video_vals):\n",
    "    video_stance, video_sentiment = video_vals   \n",
    "    \n",
    "    return f\"\"\" \n",
    "        Contexto: {context}\n",
    "    \n",
    "        Instrucción: Clasifica el siguiente mensaje teniendo en cuenta el contexto dado. El video tiene un sentimiento {video_sentiment} y una postura {video_stance} respecto a la siguiente afirmacion o pregunta {subject}.\n",
    "        Clasifica el siguiente mensaje en dos escalas, la primera es la de Likert y la segunda es la de polaridad o sentimiento. Para la escala Likert\n",
    "        ten en cuenta las siguientes opciones: 1:'Completamente en desacuerdo', 2:'En desacuerdo', 3:'Ni de acuerdo ni en desacuerdo', 4:'De acuerdo', 5:'Completamente de acuerdo'.\n",
    "        Para la escala de polaridad ten en cuenta las siguientes opciones: 1:'Negativo', 2:'Neutro', 3:'Positivo'.\n",
    "\n",
    "        Solo responde con una de las etiquetas mencionadas (solo el número) sin ningún texto adicional. Por ejemplo \"1,2\" o \"3,1\" o \"5,3\", donde el primer numero sea\n",
    "        la escala Likert y el segundo la escala de polaridad o sentimiento.\n",
    "        \"\"\"\n",
    "\n",
    "def replied_comment_promt(context,subject, video_vals, replied_message):\n",
    "    video_stance, video_sentiment = video_vals   \n",
    "    \n",
    "    return f\"\"\" \n",
    "        Contexto: {context}\n",
    "    \n",
    "        Instrucción: Clasifica el siguiente mensaje teniendo en cuenta el contexto dado. El video tiene un sentimiento {video_sentiment} y una postura {video_stance} respecto a la siguiente afirmacion o pregunta {subject}.\n",
    "        El mensaje a clasificar es una respuesta a otro mensaje, el mensaje al que responde es: {replied_message}.\n",
    "        Clasifica el siguiente mensaje en dos escalas, la primera es la de Likert y la segunda es la de polaridad o sentimiento. Para la escala Likert\n",
    "        ten en cuenta las siguientes opciones: 1:'Completamente en desacuerdo', 2:'En desacuerdo', 3:'Ni de acuerdo ni en desacuerdo', 4:'De acuerdo', 5:'Completamente de acuerdo'.\n",
    "        Para la escala de polaridad ten en cuenta las siguientes opciones: 1:'Negativo', 2:'Neutro', 3:'Positivo'.\n",
    "\n",
    "        Solo responde con una de las etiquetas mencionadas (solo el número) sin ningún texto adicional. Por ejemplo \"1,2\" o \"3,1\" o \"5,3\", donde el primer numero sea\n",
    "        la escala Likert y el segundo la escala de polaridad o sentimiento.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in dfC.iterrows():\n",
    "    if pd.notnull(dfC.at[i, 'classification']):\n",
    "        continue\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing row {i}/{len(dfC)}\")\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"saving progress {i}/{len(dfC)}\")\n",
    "        dfC.to_csv(fileC, index=False)\n",
    "\n",
    "    text = row['text']\n",
    "    video_vals = dfV.loc[dfV['video_id'] == row['video_id'], ['classification', 'polarity']].values[0]\n",
    "    video_stance = get_classification_tag(video_vals[0])\n",
    "    video_sentiment = get_sentiment_tag(video_vals[1])  \n",
    "\n",
    "    if row['is_reply']:\n",
    "        try: \n",
    "            replied_message = df.loc[df['comment_id'] == row['reply_to_comment_id'], 'text'].values[0]   \n",
    "            prompt = replied_comment_promt(context,subject, (video_stance, video_sentiment), replied_message)\n",
    "        except:\n",
    "            print(f\"Error: {row['reply_to_comment_id']} not found in df ({i})\")\n",
    "            prompt = comment_prompt(context,subject, (video_stance, video_sentiment))        \n",
    "    else:\n",
    "        prompt = comment_prompt(context,subject, (video_stance, video_sentiment))\n",
    "    \n",
    "    try:\n",
    "        # Check if is needed to wait\n",
    "        estimated_tokens = 800  # This value can be adjusted (an estimated in this case is 650, but we add 150 for safety)\n",
    "        wait_if_needed(estimated_tokens)\n",
    "\n",
    "        response = openAI_classificator(prompt, text)\n",
    "        classification, polarity = response[0].split(\",\")\n",
    "        used_tokens = response[1]\n",
    "\n",
    "        # Guarda los resultados\n",
    "        dfC.at[i, 'classification'] = classification\n",
    "        dfC.at[i, 'polarity'] = polarity\n",
    "\n",
    "        # Añade a la ventana de tokens\n",
    "        token_window.append((time.time(), used_tokens))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la fila {i}: {e}\")\n",
    "        dfC.at[i, 'classification'] = 'error'\n",
    "        dfC.at[i, 'polarity'] = 'error'\n",
    "    \n",
    "    if i == len(dfC):\n",
    "            # Save the dataframe at the end\n",
    "            dfC.to_csv(fileC, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3baa204",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
