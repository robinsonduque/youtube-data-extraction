{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59fb74-95ef-430e-a3a7-edb468108787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def classify_sentiment_vader(comment, analyzer):\n",
    "    # Obtener el puntaje de sentimiento\n",
    "    sentiment_score = analyzer.polarity_scores(str(comment))['compound']\n",
    "    \n",
    "    # Clasificar según el puntaje\n",
    "    if sentiment_score > 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score < -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def classify_comments_vader(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiments = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        sentiment = classify_sentiment_vader(row['cleaned_comment'], analyzer)\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "        if i % 10000 == 0 and i > 0:\n",
    "            print(f\"Clasificados {i} comentarios...\")\n",
    "\n",
    "    df['sentiment_Vader'] = sentiments\n",
    "    df.to_csv('../data/comments_with_sentiment.csv', index=False)\n",
    "    print(\"Los comentarios con clasificación de sentimiento VADER han sido guardados.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clasificar los comentarios usando VADER\n",
    "classified_comments_vader = classify_comments_vader('../data/cleaned_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119aa991-d3df-4e23-b8d4-3a0bf3f1f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_comments_vader['sentiment_Vader'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e5151-7919-410d-9226-2e1bf15901b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d53a0a-4591-42dd-b8c4-384cf29070e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "\n",
    "def classify_sentiment_bert(comment, analyzer):\n",
    "    # Obtener el puntaje de sentimiento\n",
    "    sentiment_score = analyzer(str(comment))\n",
    "    \n",
    "    # Clasificar según el puntaje\n",
    "    if sentiment_score[0][\"label\"] == \"POS\":\n",
    "        return 'Positive'\n",
    "    elif sentiment_score[0][\"label\"] == \"NEG\":\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def classify_comments_bert(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    analyzer = pipeline(\"sentiment-analysis\", model=\"pysentimiento/robertuito-sentiment-analysis\", truncation = True) \n",
    "    #Bert sólo procesa hasta 128 tokens, se habilita el truncamiento\n",
    "    \n",
    "    sentiments = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        sentiment = classify_sentiment_bert(row['cleaned_comment'], analyzer)\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            print(f\"Clasificados {i} comentarios...\")\n",
    "\n",
    "    df['sentiment_Bert'] = sentiments\n",
    "    df.to_csv('../data/comments_with_sentiment.csv', index=False)\n",
    "    print(\"Los comentarios con clasificación de sentimiento Bert han sido guardados.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clasificar los comentarios usando Bert\n",
    "classified_comments_bert = classify_comments_bert('../data/comments_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34656d8b-2199-4015-b938-7dcd831c759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_comments_bert['sentiment_Bert'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0ec13-c85b-44e8-a4a6-775e3768b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame Preparation for GPT-Based Stance Classification\n",
    "#\n",
    "# This DataFrame is part of a pipeline to classify the **Stance** of user comments\n",
    "# on YouTube videos, based on the video's summarized content and sentiment.\n",
    "#\n",
    "# Previous Processing Steps:\n",
    "# 1. Captions (CC) from each video were extracted.\n",
    "# 2. We summarized the captions using the Sumy library.\n",
    "#    ➤ These summaries were stored in the column `\"summary_Sumy\"`.\n",
    "# 3. We used GPT to classify each video’s overall tone and position (Stance) regarding\n",
    "#    a specific topic of interest.\n",
    "#    ➤ Two columns were generated:\n",
    "#       - `\"video_Sentiment\"`: General sentiment of the video summary (\"POS\", \"NEG\", \"NEU\").\n",
    "#       - `\"video_Stance\"`: A stance classification on a 5-point **Likert scale**:\n",
    "#         `0 = Totally disagree`, `1 = Disagree`, `2 = Neutral`, `3 = Agree`, `4 = Totally agree`.\n",
    "#\n",
    "# Objective:\n",
    "# To classify the **stance of user comments** based on:\n",
    "# - The video summary (`summary_Sumy`)\n",
    "# - The video sentiment (`video_Sentiment`)\n",
    "# - The video stance (`video_Stance`)\n",
    "\n",
    "# Viveo Comment-Based Stance Classification\n",
    "#\n",
    "# This allows us to build a context-aware stance classifier, where GPT can be prompted to answer:\n",
    "#\n",
    "# Prompt Example (Reply to a video):\n",
    "# \"This video is about: {summary_Sumy}. It has a general sentiment of {video_Sentiment}, and a stance of {video_Stance} on the topic.\n",
    "# Given this context, classify the user's {comment} in a 5-point Likert scale (0–4) according to their stance on the topic discussed... also include de sentiment.\"\n",
    "#\n",
    "#\n",
    "#\n",
    "# Reply-Based Stance Classification\n",
    "#\n",
    "# In cases where a user comment is a **reply** to another user's comment,\n",
    "# we provide GPT with additional context by including the original comment in the prompt.\n",
    "#\n",
    "# Prompt Example (Reply Case):\n",
    "# \"This video is about: {summary_Sumy}. It has a general sentiment of {video_Sentiment}, \n",
    "# and a stance of {video_Stance} on the topic.\n",
    "#\n",
    "# The user is replying to the comment: '{reply}'\n",
    "# The reply is: '{replied_comment}'\n",
    "#\n",
    "# Given this context, classify the reply's stance in a 5-point Likert scale (0–4) \n",
    "# according to its alignment with the topic discussed in the video.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18daf9-7266-4d44-8bca-5abc89a1d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_replied_comment_column(csv_path):\n",
    "    \n",
    "    # Cargar el archivo de comentarios\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "\n",
    "    # Crear un diccionario que mapea comment_id → comment_text\n",
    "    comment_lookup = df.set_index('comment_id')['cleaned_comment'].to_dict()\n",
    "\n",
    "    # Función para recuperar el texto del comentario al que se respondió\n",
    "    def get_replied_text(row):\n",
    "        if row.get('is_reply') == True or row.get('is_reply') == 'True':\n",
    "            reply_to_id = row.get('reply_to_comment_id')\n",
    "            return comment_lookup.get(reply_to_id, None)\n",
    "            \n",
    "        return np.nan\n",
    "\n",
    "    # Aplicar la función y crear la nueva columna\n",
    "    df['replied_comment'] = df.apply(get_replied_text, axis=1)\n",
    "\n",
    "    # Guardar los cambios en el mismo archivo\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Columna 'replied_comment' añadida correctamente a: {csv_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Ejecutar la función\n",
    "updated_df = add_replied_comment_column('../data/comments_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e2cd3-8148-4c83-a997-d29c4e71b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment_gpt(comment, analyzer):\n",
    "    return 'None'\n",
    "\n",
    "def classify_comments_gpt(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    \n",
    "\n",
    "    df['sentiment_GPT'] = \"\"\n",
    "    df['likert_GPT'] = \"\"\n",
    "    df.to_csv('../data/comments_with_sentiment.csv', index=False)\n",
    "    print(\"Los comentarios con clasificación de sentimiento GPT han sido guardados.\")\n",
    "    print(\"Los comentarios con clasificación de posición GPT han sido guardados.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clasificar los comentarios usando GPT\n",
    "classified_comments_gpt = classify_comments_gpt('../data/comments_with_sentiment.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
